<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="神经网络算法"><meta name="keywords" content="Python"><meta name="author" content="故人酒,undefined"><meta name="copyright" content="故人酒"><title>神经网络算法【故人酒的博客】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="icon" href="/favicon.ico"><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="/js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#实现方法搭建基本模块——神经元"><span class="toc-number">1.</span> <span class="toc-text">实现方法搭建基本模块——神经元</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#代码实现"><span class="toc-number">1.1.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#搭建神经网络"><span class="toc-number">2.</span> <span class="toc-text">搭建神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#代码实现-1"><span class="toc-number">2.1.</span> <span class="toc-text">代码实现</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">故人酒</div><div class="author-info-description">努力向上。</div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/hebangan" target="_blank">GitHub<i class="icon-dot bg-color10"></i></a><a class="links-button button-hover" href="mailto:1820500218@qq.com" target="_blank">E-Mail<i class="icon-dot bg-color3"></i></a><a class="links-button button-hover" href="tencent://message/?uin=1820500218&amp;Site=&amp;Menu=yes" target="_blank">QQ<i class="icon-dot bg-color1"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="/archives"><span class="pull-top">日志</span><span class="pull-bottom">78</span></a><a class="author-info-articles-tags article-meta" href="/tags"><span class="pull-top">标签</span><span class="pull-bottom">22</span></a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="title-name" href="/">故人酒的博客</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">神经网络算法</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2020-04-16 | 更新于 2020-04-16</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Python/">Python</a></div></div></div><div class="main-content"><h1 id="实现方法搭建基本模块——神经元"><a href="#实现方法搭建基本模块——神经元" class="headerlink" title="实现方法搭建基本模块——神经元"></a>实现方法搭建基本模块——神经元</h1><p>在说神经网络之前，我们讨论一下神经元（Neurons），它是神经网络的基本单元。神经元先获得输入，然后执行某些数学运算后，再产生一个输出。比如一个2输入神经元的例子：在这个神经元中，输入总共经历了3步数学运算，<br>先将两个输入乘以<strong>权重</strong>（weight）：<br>x1→x1 × w1</p>
<p>x2→x2 × w2</p>
<p>把两个结果想加，再加上一个<strong>偏置</strong>（bias）：</p>
<p>（x1 × w1）+（x2 × w2）+ b</p>
<p>最后将它们经过<strong>激活函数</strong>（activation function）处理得到输出：</p>
<p>y = f(x1 × w1 + x2 × w2 + b)</p>
<p>激活函数的作用是将无限制的输入转换为可预测形式的输出。一种常用的激活函数是sigmoid函数：sigmoid函数的输出介于0和1，我们可以理解为它把 (−∞,+∞) 范围内的数压缩到 (0, 1)以内。正值越大输出越接近1，负向数值越大输出越接近0。</p>
<p>举个例子，上面神经元里的权重和偏置取如下数值：<br>w=[0,1]<br>b = 4<br>w=[0,1]是w1=0、w2=1的向量形式写法。给神经元一个输入x=[2,3]，可以用向量点积的形式把<strong>神经元的输出</strong>计算出来：<br>w·x+b =（x1 × w1）+（x2 × w2）+ b = 0×2+1×3+4=7<br>y=f(w⋅X+b)=f(7)=0.999</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="comment"># Our activation function: f(x) = 1 / (1 + e^(-x))</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Neuron</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, weights, bias)</span>:</span></span><br><span class="line">   self.weights = weights</span><br><span class="line">   self.bias = bias</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">feedforward</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">  <span class="comment"># Weight inputs, add bias, then use the activation function</span></span><br><span class="line">   total = np.dot(self.weights, inputs) + self.bias</span><br><span class="line">   <span class="keyword">return</span> sigmoid(total)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"> weights = np.array([<span class="number">0</span>, <span class="number">1</span>]) <span class="comment"># w1 = 0, w2 = 1</span></span><br><span class="line"> bias = <span class="number">4</span> <span class="comment"># b = 4</span></span><br><span class="line"> n = Neuron(weights, bias)</span><br><span class="line"> x = np.array([<span class="number">2</span>, <span class="number">3</span>]) <span class="comment"># x1 = 2, x2 = 3</span></span><br><span class="line"> print(n.feedforward(x)) <span class="comment"># 0.9990889488055994</span></span><br></pre></td></tr></table></figure>

<h1 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a>搭建神经网络</h1><p>神经网络就是把一堆神经元连接在一起。</p>
<p>这个网络有2个输入、一个包含2个神经元的隐藏层（h1和h2）、包含1个神经元的输出层o1。</p>
<p>隐藏层是夹在输入输入层和输出层之间的部分，一个神经网络可以有多个隐藏层。</p>
<p>把神经元的输入向前传递获得输出的过程称为<strong>前馈</strong>（feedforward）。</p>
<p>我们假设上面的网络里所有神经元都具有相同的权重w=[0,1]和偏置b=0，激活函数都是sigmoid，那么我们会得到什么输出呢？</p>
<p>h1=h2=f(w⋅x+b)=f((0×2)+(1×3)+0)</p>
<p>=f(3)</p>
<p>=0.9526</p>
<p>o1=f(w⋅[h1,h2]+b)=f((0∗h1)+(1∗h2)+0)</p>
<p>=f(0.9526)</p>
<p>=0.7216</p>
<h2 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="comment"># Our activation function: f(x) = 1 / (1 + e^(-x))</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Neuron</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, weights, bias)</span>:</span></span><br><span class="line">   self.weights = weights</span><br><span class="line">   self.bias = bias</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">feedforward</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">  <span class="comment"># Weight inputs, add bias, then use the activation function</span></span><br><span class="line">   total = np.dot(self.weights, inputs) + self.bias</span><br><span class="line">   <span class="keyword">return</span> sigmoid(total)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OurNeuralNetwork</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        weights = np.array([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">        bias = <span class="number">0</span></span><br><span class="line">        <span class="comment"># The Neuron class here is from the previous section</span></span><br><span class="line">        self.h1 = Neuron(weights, bias)</span><br><span class="line">        self.h2 = Neuron(weights, bias)</span><br><span class="line">        self.o1 = Neuron(weights, bias)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedforward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out_h1 = self.h1.feedforward(x)</span><br><span class="line">        out_h2 = self.h2.feedforward(x)</span><br><span class="line">        <span class="comment"># The inputs for o1 are the outputs from h1 and h2</span></span><br><span class="line">        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))</span><br><span class="line">        <span class="keyword">return</span> out_o1</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    network = OurNeuralNetwork()</span><br><span class="line">    x = np.array([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">    print(network.feedforward(x)) <span class="comment"># 0.7216325609518421训练神经网络</span></span><br></pre></td></tr></table></figure>

</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">故人酒</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="https://hebangan.github.io/2020/04/16/python/神经网络算法/">https://hebangan.github.io/2020/04/16/python/神经网络算法/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://hebangan.github.io">故人酒的博客</a>！</span></div></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2020/05/16/Vue/MVC和MVVM的区别/"><i class="fas fa-angle-left">&nbsp;</i><span>MVC和MVVM的区别</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2020/04/16/python/图形识别/"><span>图像识别</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2018 ～ 2020 By 故人酒</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/autoload.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas-particle.js"></script><!--script(src=url)--></body></html>